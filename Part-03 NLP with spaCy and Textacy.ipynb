{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leveraging Linguistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to pick up a simple use case and see how we can solve that. Then, we repeat this again, but on a slighlty different text corpus and so on. \n",
    "\n",
    "This helps us learn build intuition on how to use linguistics in NLP. As mentioned, I am going to use spaCy here, but you are free to use NLTK or anything else available in your favourite progamming language\n",
    "\n",
    "## Grammar Crash Course and spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy # for visualization\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is an error above, try:\n",
    "- Windows Shell:```python -m spacy download en``` as **Administrator**\n",
    "- Linux Terminal:```sudo python -m spacy download en ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first half talks about NLP pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redacting Names with Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Madam Pomfrey, the nurse, was kept busy by a sudden spate of colds among the staff and students. Her Pepperup potion worked instantly, though it left the drinker smoking at the ears for several hours afterward. Ginny Weasley, who had been looking pale, was bullied into taking some by Percy.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the text with spaCy. This runs the entire pipeline.\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pomfrey (PERSON)\n",
      "Pepperup (ORG)\n",
      "several hours (TIME)\n",
      "Ginny Weasley (PERSON)\n",
      "Percy (PERSON)\n"
     ]
    }
   ],
   "source": [
    "# 'doc' now contains a parsed version of text. We can use it to do anything we want!\n",
    "# For example, this will print out all the named entities that were detected:\n",
    "for entity in doc.ents:\n",
    "    print(f\"{entity.text} ({entity.label_})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: Explain the entity and entity labels above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redact_names(text):\n",
    "    doc = nlp(text)\n",
    "    redacted_sentence = []\n",
    "    for token in doc:\n",
    "        if token.ent_type_ == \"PERSON\":\n",
    "            redacted_sentence.append(\"[REDACTED]\")\n",
    "        else:\n",
    "            redacted_sentence.append(token.string)\n",
    "    return \"\".join(redacted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Madam [REDACTED], the nurse, was kept busy by a sudden spate of colds among the staff and students. Her Pepperup potion worked instantly, though it left the drinker smoking at the ears for several hours afterward. [REDACTED][REDACTED], who had been looking pale, was bullied into taking some by [REDACTED].'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redact_names(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redact_names(text):\n",
    "    doc = nlp(text)\n",
    "    redacted_sentence = []\n",
    "    for ent in doc.ents:\n",
    "        ent.merge()\n",
    "    for token in doc:\n",
    "        if token.ent_type_ == \"PERSON\":\n",
    "            redacted_sentence.append(\"[REDACTED]\")\n",
    "        else:\n",
    "            redacted_sentence.append(token.string)\n",
    "    return \"\".join(redacted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Madam [REDACTED], the nurse, was kept busy by a sudden spate of colds among the staff and students. Her Pepperup potion worked instantly, though it left the drinker smoking at the ears for several hours afterward. [REDACTED], who had been looking pale, was bullied into taking some by [REDACTED].'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redact_names(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_text_entities(text):\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        print(f'{ent}, Label: {ent.label_}, {spacy.explain(ent.label_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla, Label: ORG, Companies, agencies, institutions, etc.\n",
      "20%, Label: PERCENT, Percentage, including \"%\"\n",
      "the months, Label: DATE, Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "explain_text_entities('Tesla has gained 20% market share in the months since')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taj Mahal, Label: PERSON, People, including fictional\n",
      "Mughal, Label: NORP, Nationalities or religious or political groups\n",
      "Shah Jahan, Label: PERSON, People, including fictional\n",
      "Yamuna, Label: LOC, Non-GPE locations, mountain ranges, bodies of water\n",
      "Agra, Label: GPE, Countries, cities, states\n",
      "India, Label: GPE, Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "explain_text_entities('Taj Mahal built by Mughal Emperor Shah Jahan stands tall on the banks of Yamuna in modern day Agra, India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ashoka, Label: PERSON, People, including fictional\n",
      "Indian, Label: NORP, Nationalities or religious or political groups\n"
     ]
    }
   ],
   "source": [
    "explain_text_entities('Ashoka was a great Indian king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ashoka University, Label: ORG, Companies, agencies, institutions, etc.\n",
      "the Young India Fellowship, Label: ORG, Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "explain_text_entities('The Ashoka University sponsors the Young India Fellowship')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Generation with PoS Tagging\n",
    "\n",
    "Sometimes, we want to quickly pull out keywords, or keyphrases from a larger body of text. This helps us mentally paint a picture of what this text is about. This is particularly helpful in analysis of texts like long emails or essays. \n",
    "\n",
    "We refer to these as noun chunks. Noun chunks are _noun phrases_ - not a single word, but a short phrase which describes the noun. For example, \"the blue skies\" or \"the worldâ€™s largest conglomerate\". \n",
    "\n",
    "To get the noun chunks in a document, simply iterate over `doc.noun_chunks`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = 'Bansoori is an Indian classical instrument. Tom plays Bansoori and Guitar.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1 Bansoori\n",
      "sentence1 an Indian classical instrument\n",
      "sentence2 Tom\n",
      "sentence2 Bansoori\n",
      "sentence2 Guitar\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(doc.sents):\n",
    "    for noun in sentence.noun_chunks:\n",
    "        print(f'sentence{idx+1}', noun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our example text has two sentences, we can pull out noun phrase chunks from each sentence. We pull out noun phrases instead of single words. This means, we are able to pull out 'an Indian classical instrument' as one noun. This is quite useful as we will see in a moment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's take a quick look at all parts-of-speech tags in our example text. We will use the verbs and adjectives to write some simple question generating logic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bansoori PROPN NNP\n",
      "is VERB VBZ\n",
      "an DET DT\n",
      "Indian ADJ JJ\n",
      "classical ADJ JJ\n",
      "instrument NOUN NN\n",
      ". PUNCT .\n",
      "Tom PROPN NNP\n",
      "plays VERB VBZ\n",
      "Bansoori PROPN NNP\n",
      "and CCONJ CC\n",
      "Guitar PROPN NNP\n",
      ". PUNCT .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that here 'instrument' is tagged as a NOUN while 'Indian' and 'classical' are tagged as adjectives. This makes sense. Addititionally, Bansoor and Guitar are tagged as PROPN or Proper Nouns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nouns vs Proper Noun** \n",
    "Nouns name people, places, and things. Common nouns name general items like waiter, jeans, country. Proper nouns name specific things like Roger, Levi's, India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruleset = [\n",
    "    {\n",
    "        'id': 1, \n",
    "        'req_tags': ['NNP', 'VBZ', 'NN'],\n",
    "    }, \n",
    "    {\n",
    "        'id': 2, \n",
    "        'req_tags': ['NNP', 'VBZ'],\n",
    "    }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'req_tags': ['NNP', 'VBZ', 'NN']}, {'id': 2, 'req_tags': ['NNP', 'VBZ']}]\n"
     ]
    }
   ],
   "source": [
    "print(ruleset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_tag(doc, tag):\n",
    "    return [tok for tok in doc if tok.tag_ == tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bansoori is an Indian classical instrument.\n",
      "What is Bansoori?\n",
      "Tom plays Bansoori and Guitar.\n",
      "What does Tom play?\n"
     ]
    }
   ],
   "source": [
    "def sent_to_ques(sent):\n",
    "    doc = nlp(sent)\n",
    "    pos_tags = [token.tag_ for token in doc]\n",
    "    for idx, rule in enumerate(ruleset):\n",
    "        if rule['id'] == 1:\n",
    "            if all(key in pos_tags for key in rule['req_tags']): \n",
    "                print(sent)\n",
    "                NNP = get_pos_tag(doc, \"NNP\")\n",
    "                NNP = str(NNP[0])\n",
    "                VBZ = get_pos_tag(doc, \"VBZ\")\n",
    "#                 subjects = get_subjects_of_verb(VBZ[0])\n",
    "#                 print(subjects)\n",
    "                VBZ = str(VBZ[0])\n",
    "                ques = f'What {VBZ} {NNP}?'\n",
    "                return(ques)\n",
    "        if rule['id'] == 2:\n",
    "            if all(key in pos_tags for key in rule['req_tags']): #'NNP', 'VBZ' in sentence.\n",
    "                print(sent)\n",
    "                NNP = get_pos_tag(doc, \"NNP\")\n",
    "                NNP = str(NNP[0])\n",
    "                VBZ = get_pos_tag(doc, \"VBZ\")\n",
    "                VBZ = str(VBZ[0].lemma_)\n",
    "                ques = f'What does {NNP} {VBZ}?'\n",
    "                return (ques)\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent_to_ques(str(sent)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Generation using Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a dependency parser? \n",
    "\n",
    "> A dependency parser analyzes the grammatical structure of a sentence, establishing relationships between \"head\" words and words which modify those heads.\n",
    "> from [Stanford NNDEP Project](https://nlp.stanford.edu/software/nndep.html)\n",
    "\n",
    "A dependency parser helps us understand the various ways in which parts of the sentence interact or depend on each other. For instance, how is the noun modified by adjectives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bansoori nsubj\n",
      "is ROOT\n",
      "an det\n",
      "Indian amod\n",
      "classical amod\n",
      "instrument attr\n",
      ". punct\n",
      "Tom nsubj\n",
      "plays ROOT\n",
      "Bansoori dobj\n",
      "and cc\n",
      "Guitar conj\n",
      ". punct\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these terms are simple enough to guess e.g. 'ROOT' is where the dependency tree might begin. 'nsubj' is the noun or nominal subject. 'cc' is probably conjunction. But this is still incomplete, luckily for us, spaCy includes the nifty `explain()` function to help us interpret these.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bansoori nsubj nominal subject\n",
      "is ROOT None\n",
      "an det determiner\n",
      "Indian amod adjectival modifier\n",
      "classical amod adjectival modifier\n",
      "instrument attr attribute\n",
      ". punct punctuation\n",
      "Tom nsubj nominal subject\n",
      "plays ROOT None\n",
      "Bansoori dobj direct object\n",
      "and cc coordinating conjunction\n",
      "Guitar conj conjunct\n",
      ". punct punctuation\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, token.dep_, spacy.explain(token.dep_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a good starting point to Google away and pick up some linguistics specific terms. E.g. a 'conjunct' is often used to connect two clauses. 'attribute' is simply a way to highlight something which is a property of the nominal subject. \n",
    "\n",
    "Nominal subjects are usually nouns or pronouns which in turns are actors (via verbs) or have properties(via attributes). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Relationship\n",
    "\n",
    "spaCy has an inbuilt tool called displacy for displaying simple, but clean and powerful visualizations. It offers two primary modes: Named Entity Recognition and Dependency Parsing. Here we will use the 'dep' or dependency mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1975\" height=\"487.0\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial\"><text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\"><tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Bansoori</tspan><tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan></text><text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\"><tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan><tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan></text><text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\"><tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">an</tspan><tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan></text><text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\"><tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">Indian</tspan><tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan></text><text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\"><tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">classical</tspan><tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADJ</tspan></text><text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\"><tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">instrument.</tspan><tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan></text><text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\"><tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Tom</tspan><tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan></text><text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\"><tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">plays</tspan><tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">VERB</tspan></text><text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\"><tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">Bansoori</tspan><tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PROPN</tspan></text><text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\"><tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">and</tspan><tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">CCONJ</tspan></text><text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\"><tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">Guitar.</tspan><tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PROPN</tspan></text><g class=\"displacy-arrow\"><path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/><text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"><textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath></text><path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/></g><g class=\"displacy-arrow\"><path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M420,352.0 C420,89.5 920.0,89.5 920.0,352.0\" fill=\"none\" stroke=\"currentColor\"/><text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"><textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath></text><path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/></g><g class=\"displacy-arrow\"><path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M595,352.0 C595,177.0 915.0,177.0 915.0,352.0\" fill=\"none\" stroke=\"currentColor\"/><text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"><textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath></text><path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/></g><g class=\"displacy-arrow\"><path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/><text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"><textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath></text><path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/></g><g class=\"displacy-arrow\"><path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M245,352.0 C245,2.0 925.0,2.0 925.0,352.0\" fill=\"none\" stroke=\"currentColor\"/><text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"><textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath></text><path class=\"displacy-arrowhead\" d=\"M925.0,354.0 L933.0,342.0 917.0,342.0\" fill=\"currentColor\"/></g><g class=\"displacy-arrow\"><path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/><text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"><textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath></text><path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/></g><g class=\"displacy-arrow\"><path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/><text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"><textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath></text><path class=\"displacy-arrowhead\" d=\"M1435.0,354.0 L1443.0,342.0 1427.0,342.0\" fill=\"currentColor\"/></g><g class=\"displacy-arrow\"><path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,264.5 1610.0,264.5 1610.0,352.0\" fill=\"none\" stroke=\"currentColor\"/><text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"><textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath></text><path class=\"displacy-arrowhead\" d=\"M1610.0,354.0 L1618.0,342.0 1602.0,342.0\" fill=\"currentColor\"/></g><g class=\"displacy-arrow\"><path class=\"displacy-arc\" id=\"arrow-0-8\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,177.0 1790.0,177.0 1790.0,352.0\" fill=\"none\" stroke=\"currentColor\"/><text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\"><textPath xlink:href=\"#arrow-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath></text><path class=\"displacy-arrowhead\" d=\"M1790.0,354.0 L1798.0,342.0 1782.0,342.0\" fill=\"currentColor\"/></g></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep', minify=True, jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the first sentence for a quick study: We see that \"instrument\" is \"amod\" or adjectively modified by \"Indian classicial\". We pulled this phrase earlier as a noun chunk. \n",
    "\n",
    "This means that when we pulled noun phrase chunks out of this sentence, spaCy must have finished dependency parsing already under the hood. \n",
    "\n",
    "Also notice the direction of arrows, while the NOUN (instrument) is modified by ADJ. It is the 'attr' of the ROOT VERB (is). \n",
    "\n",
    "\n",
    "This logical tree structure of simple sentences is what we will exploit to simplify our question generation. Let's write some functions to extract these dependency entities in the spaCy token format i.e. without converting them to strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_main_verbs_of_sent(sent):\n",
    "    \"\"\"Return the main (non-auxiliary) verbs in a sentence.\"\"\"\n",
    "    return [tok for tok in sent\n",
    "            if tok.pos_ == 'VERB' and tok.dep_ not in {'aux', 'auxpass'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are to ask questions from someone, they often are around a piece of information e.g. What is the capital of India? or around some action e.g. What did you do on Sunday?\n",
    "\n",
    "Of course, there are other types of questions around Who, Where, Why and so on. \n",
    "\n",
    "Extend the approach below to at least add Who, Where and When questions as practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_conjuncts(tok):\n",
    "    \"\"\"\n",
    "    Return conjunct dependents of the leftmost conjunct in a coordinated phrase,\n",
    "    e.g. \"Burton, [Dan], and [Josh] ...\".\n",
    "    \"\"\"\n",
    "    return [right for right in tok.rights\n",
    "            if right.dep_ == 'conj']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjects_of_verb(verb):\n",
    "    SUBJ_DEPS = {'agent', 'csubj', 'csubjpass', 'expl', 'nsubj', 'nsubjpass'}\n",
    "    \"\"\"Return all subjects of a verb according to the dependency parse.\"\"\"\n",
    "    subjs = [tok for tok in verb.lefts\n",
    "             if tok.dep_ in SUBJ_DEPS]\n",
    "    # get additional conjunct subjects\n",
    "    subjs.extend(tok for subj in subjs for tok in _get_conjuncts(subj))\n",
    "    return subjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level Up: Question and Answer\n",
    "So far, we have been trying to generate questions. But if you were trying to make an automated quiz for students, you would also need to mine the right answer. \n",
    "\n",
    "The answer in this case will be simply the objects of verb. What is an object of verb? \n",
    "\n",
    "> In the sentence, \"Give the book to me,\" \"book\" is the direct object of the verb \"give,\" and \"me\" is the indirect object. - from the Cambridge English Dictionary\n",
    "\n",
    "Loosely, object is the piece on which our verb acts. This is almost always the answer to our \"what\". Let's write a question to find the objects of any verb: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_objects_of_verb(verb):\n",
    "    \"\"\"\n",
    "    Return all objects of a verb according to the dependency parse,\n",
    "    including open clausal complements.\n",
    "    \"\"\"\n",
    "    OBJ_DEPS = {'attr', 'dobj', 'dative', 'oprd'}\n",
    "    objs = [tok for tok in verb.rights\n",
    "            if tok.dep_ in OBJ_DEPS]\n",
    "    # get open clausal complements (xcomp)\n",
    "    objs.extend(tok for tok in verb.rights\n",
    "                if tok.dep_ == 'xcomp')\n",
    "    # get additional conjunct objects\n",
    "    objs.extend(tok for obj in objs for tok in _get_conjuncts(obj))\n",
    "    return objs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the output of our functions for the example text. The first is the sentence itself, then the root verb, than the lemma form of that verb, followed by subjects of the verb and then objects.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bansoori is an Indian classical instrument. is be [Bansoori] [instrument]\n",
      "Tom plays Bansoori and Guitar. plays play [Tom] [Bansoori, Guitar]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(example_text)\n",
    "for sentence in doc.sents:\n",
    "    print(sentence, sentence.root, sentence.root.lemma_, get_subjects_of_verb(sentence.root), get_objects_of_verb(sentence.root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's arrange the pieces above into a neat function which we can then re-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What is Bansoori?', 'answers': [instrument]},\n",
       " {'question': 'What does Tom play?', 'answers': [Bansoori, Guitar]}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def para_to_ques(eg_text):\n",
    "    doc = nlp(eg_text)\n",
    "    results = []\n",
    "    for sentence in doc.sents:\n",
    "        root = sentence.root\n",
    "        ask_about = get_subjects_of_verb(root)\n",
    "        answers = get_objects_of_verb(root)\n",
    "        if len(ask_about) > 0 and len(answers) > 0:\n",
    "            if root.lemma_ == \"be\":\n",
    "                question = f'What {root} {ask_about[0]}?'\n",
    "            else:\n",
    "                question = f'What does {ask_about[0]} {root.lemma_}?'\n",
    "            results.append({'question':question, 'answers':answers})\n",
    "    return results\n",
    "para_to_ques(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems right to me. Let's run this on a larger sample of sentences. This sample has varying degrees of complexities and sentence structures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_example_text = \"\"\"\n",
    "Puliyogare is a South Indian dish made of rice and tamarind. \n",
    "Priya writes poems. Shivangi bakes cakes. Sachin sings in the orchestra.\n",
    "\n",
    "Osmosis is the movement of a solvent across a semipermeable membrane toward a higher concentration of solute. In biological systems, the solvent is typically water, but osmosis can occur in other liquids, supercritical liquids, and even gases.\n",
    "When a cell is submerged in water, the water molecules pass through the cell membrane from an area of low solute concentration to high solute concentration. For example, if the cell is submerged in saltwater, water molecules move out of the cell. If a cell is submerged in freshwater, water molecules move into the cell.\n",
    "\n",
    "Raja-Yoga is divided into eight steps. The first is Yama. Yama is nonviolence, truthfulness, continence, and non-receiving of any gifts.\n",
    "After Yama, Raja-Yoga has Niyama. cleanliness, contentment, austerity, study, and self - surrender to God.\n",
    "The steps are Yama and Niyama. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What is Puliyogare?', 'answers': [dish]},\n",
       " {'question': 'What does Priya write?', 'answers': [poems]},\n",
       " {'question': 'What does Shivangi bake?', 'answers': [cakes]},\n",
       " {'question': 'What is Osmosis?', 'answers': [movement]},\n",
       " {'question': 'What is solvent?', 'answers': [water]},\n",
       " {'question': 'What is first?', 'answers': [Yama]},\n",
       " {'question': 'What is Yama?',\n",
       "  'answers': [nonviolence, truthfulness, continence, of]},\n",
       " {'question': 'What does Yoga have?', 'answers': [Niyama]},\n",
       " {'question': 'What are steps?', 'answers': [Yama, Niyama]}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_to_ques(large_example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facts Extraction using Semi Structured Sentence Parsing\n",
    "Introducing textacy,\n",
    "\n",
    "Boss mode with co reference resolution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
