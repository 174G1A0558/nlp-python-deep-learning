{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leveraging Linguistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to pick up a simple use case and see how we can solve that. Then, we repeat this again, but on a slighlty different text corpus and so on. \n",
    "\n",
    "This helps us learn build intuition on how to use linguistics in NLP. As mentioned, I am going to use spaCy here, but you are free to use NLTK or anything else available in your favourite progamming language\n",
    "\n",
    "## Grammar Crash Course and spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy # for visualization\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is an error above, try:\n",
    "- Windows Shell:```python -m spacy download en``` as **Administrator**\n",
    "- Linux Terminal:```sudo python -m spacy download en ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first half talks about NLP pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redacting Names with Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Madam Pomfrey, the nurse, was kept busy by a sudden spate of colds among the staff and students. Her Pepperup potion worked instantly, though it left the drinker smoking at the ears for several hours afterward. Ginny Weasley, who had been looking pale, was bullied into taking some by Percy.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the text with spaCy. This runs the entire pipeline.\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pomfrey (PERSON)\n",
      "Pepperup (ORG)\n",
      "several hours (TIME)\n",
      "Ginny Weasley (PERSON)\n",
      "Percy (PERSON)\n"
     ]
    }
   ],
   "source": [
    "# 'doc' now contains a parsed version of text. We can use it to do anything we want!\n",
    "# For example, this will print out all the named entities that were detected:\n",
    "for entity in doc.ents:\n",
    "    print(f\"{entity.text} ({entity.label_})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: Explain the entity and entity labels above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redact_names(text):\n",
    "    doc = nlp(text)\n",
    "    redacted_sentence = []\n",
    "    for token in doc:\n",
    "        if token.ent_type_ == \"PERSON\":\n",
    "            redacted_sentence.append(\"[REDACTED]\")\n",
    "        else:\n",
    "            redacted_sentence.append(token.string)\n",
    "    return \"\".join(redacted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Madam [REDACTED], the nurse, was kept busy by a sudden spate of colds among the staff and students. Her Pepperup potion worked instantly, though it left the drinker smoking at the ears for several hours afterward. [REDACTED][REDACTED], who had been looking pale, was bullied into taking some by [REDACTED].'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redact_names(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redact_names(text):\n",
    "    doc = nlp(text)\n",
    "    redacted_sentence = []\n",
    "    for ent in doc.ents:\n",
    "        ent.merge()\n",
    "    for token in doc:\n",
    "        if token.ent_type_ == \"PERSON\":\n",
    "            redacted_sentence.append(\"[REDACTED]\")\n",
    "        else:\n",
    "            redacted_sentence.append(token.string)\n",
    "    return \"\".join(redacted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Madam [REDACTED], the nurse, was kept busy by a sudden spate of colds among the staff and students. Her Pepperup potion worked instantly, though it left the drinker smoking at the ears for several hours afterward. [REDACTED], who had been looking pale, was bullied into taking some by [REDACTED].'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redact_names(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_text_entities(text):\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        print(ent, ent.label_, spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla ORG Companies, agencies, institutions, etc.\n",
      "20% PERCENT Percentage, including \"%\"\n",
      "the months DATE Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "explain_text_entities('Tesla has gained 20% market share in the months since')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taj Mahal PERSON People, including fictional\n",
      "Mughal NORP Nationalities or religious or political groups\n",
      "Shah Jahan PERSON People, including fictional\n",
      "Yamuna LOC Non-GPE locations, mountain ranges, bodies of water\n",
      "Agra GPE Countries, cities, states\n",
      "India GPE Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "explain_text_entities('Taj Mahal built by Mughal Emperor Shah Jahan stands tall on the banks of Yamuna in modern day Agra, India')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ashoka PERSON People, including fictional\n",
      "Indian NORP Nationalities or religious or political groups\n"
     ]
    }
   ],
   "source": [
    "explain_text_entities('Ashoka was a great Indian king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ashoka University ORG Companies, agencies, institutions, etc.\n",
      "the Young India Fellowship ORG Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "explain_text_entities('The Ashoka University sponsors the Young India Fellowship')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Generation with PoS Tagging and Dependency Parsing\n",
    "\n",
    "Sometimes, we want to quickly pull out keywords, or keyphrases from a larger body of text. This helps us mentally paint a picture of what this text is about. This is particularly helpful in analysis of texts like email length. \n",
    "\n",
    "We refer to these as noun chunks. Noun chunks are _noun phrases_ - not a single word, but a short phrase which describes the noun. For example, \"the blue skies\" or \"the world’s largest conglomerate\". \n",
    "\n",
    "To get the noun chunks in a document, simply iterate over Doc.noun_chunks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_sentence = 'James B. Comey, the former F.B.I. director fired by President Trump, said in an ABC News interview that Mr. Trump was “morally unfit to be president,” portraying him as a danger to the nation.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "doc = nlp(example_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James B. Comey                ,Comey          ,nsubj  ,nominal subject          ,said           \n",
      "the former F.B.I. director    ,director       ,appos  ,appositional modifier    ,Comey          \n",
      "President Trump               ,Trump          ,pobj   ,object of preposition    ,by             \n",
      "an ABC News interview         ,interview      ,pobj   ,object of preposition    ,in             \n",
      "Mr. Trump                     ,Trump          ,nsubj  ,nominal subject          ,was            \n",
      "president                     ,president      ,attr   ,attribute                ,be             \n",
      "him                           ,him            ,dobj   ,direct object            ,portraying     \n",
      "a danger                      ,danger         ,pobj   ,object of preposition    ,as             \n",
      "the nation                    ,nation         ,pobj   ,object of preposition    ,to             \n"
     ]
    }
   ],
   "source": [
    "for chunk in doc.noun_chunks:\n",
    "    print(f'{chunk.text:<30},{chunk.root.text:<15},{chunk.root.dep_:<7},{spacy.explain(chunk.root.dep_):25},{chunk.root.head.text:<15}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facts Extraction using Semi Structured Sentence Parsing\n",
    "Introducing textacy,\n",
    "\n",
    "Boss mode with co reference resolution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
