{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leveraging Linguistics for Chat\n",
    "\n",
    "There is immense utility in being able to mine long human texts for particular information or manipulate it in meaningful ways. \n",
    "\n",
    "We will take a deep dive of the linguistic features of spaCy (and mention the old Stanford NLTK, CoreNLP for reference). \n",
    "\n",
    "We will cover dependency parsing, POS Tagging, Noun Phrase Chunking and Named Entities. \n",
    "\n",
    "As mentioned in the Text Cleaning section, these are powerful in combination and not in isolation. We will learn how to use pipelines in spaCy for the same. \n",
    "\n",
    "We will start with a walkthrough of the official spaCy guidelines and code examples. This uses the pre-trained models from spaCy itself. \n",
    "\n",
    "## Linguistics\n",
    "\n",
    "### Linguistics Application: Chatbots\n",
    "Chat bots or conversational systems such as Siri need to have intricate understanding of language to do two main things: \n",
    "1. Understand human input in either text or voice\n",
    "    - this input is different from how we use search, for instance we might enter the exact item we want to buy in Amazon search but we will might Alexa for suggestions on best toys for 3 year olds\n",
    "\n",
    "2. Generate language response\n",
    "    - What does a Google search for *Steve Jobs Birthday* return for you? A list of web pages. On the other hand, you would expect Siri not only tell the exact date of Job's birth - but also a proper sentence such as: *Steve Jobs was born on 24 Feb 1955*\n",
    "\n",
    "\n",
    "The way we study language is referred to as linguistics. This section covers language concepts as applied to Natural Language Processing. \n",
    "\n",
    "We have seen some of this when we studied English Grammar back in our school days. Famously, you might want to recap the following: _noun_, _verb_, _gerund_ and so on. \n",
    "\n",
    "\n",
    "## Main Headings :\n",
    "- HEADING 1: Linguistic Roots of English Language\n",
    "- HEADING 2: Leveraging Language: Example Tasks - Chat bots and Search\n",
    "- HEADING 3: PoS Tagging, NP Chunking\n",
    "- HEADING 4: NER: Inbuilt models\n",
    "- HEADING 5: Gluing it all together\n",
    "\n",
    "## Skills learned:\n",
    "- SKILL 1: Linguistic Concepts in NLP\n",
    "- SKILL 2: Spelling Correction, Slot Filling\n",
    "- SKILL 3: Linguistic Tasks using spaCy\n",
    "- SKILL 4: NER with spaCy pipelines\n",
    "- SKILL 5: End to end spacy implementation with a toy example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slot Filling vs NER\n",
    "The goals of slot filling are different. Slot filling is looking for specific pieces of information with respect to something. For instance, you might ask Siri or Google Assistant - _Who is the spouse of Sachin Tendulkar?_\n",
    "\n",
    "In this example, you are looking for _spouse_ with respect to _Sachin Tendulkar_. \n",
    "\n",
    "Now this response information can be named entities _e.g. who is spouse of this person?_ but can also be other things _e.g. when was this person born?_ \n",
    "\n",
    "Exactly what information depends on the application, but Wikipedia info boxes are a good example. \n",
    "TKX Add Wiki info box screenshot of Sachin Tendulkar\n",
    "TKX TIP: Similar thought process is quite useful for building a chatbot, say for customer service. \n",
    "\n",
    "NER is more generic and just looks for things. When we mean things, usually they are nouns such as names, like people, companies, places, etc. Your focus is not on the relation between these things. \n",
    "\n",
    "For instance, BookMyShow allows you to book tickets via WhatsApp. \n",
    "\n",
    "TKX: Add BMS screenshots from phone\n",
    "\n",
    "TKX: This example needs to be worked out better\n",
    "The relation is a movie, which has following _slots_:date, screen, theatre/movie hall name. A NER system would just tag <Bengaluru> and <movie name> as names of things, as opposed to 'dfsdf,' which is not the name of a specific individual thing. If the sentence said 'adasda' instead of 'adasda,' NER would pick that out as a movie name. \n",
    "    \n",
    "Some NER taggers will also extract dates, money, and other numbers because they're useful, even though they're not really named entities.\n",
    "\n",
    "These tasks don't HAVE to be done using sequence tagging, either; slot-filling has been done with templates and multi-stage approaches (extract candidate phrases by tagging and then classify or rank)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy # for visualization\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is an error above, try:\n",
    "- Windows Shell:```python -m spacy download en``` as **Administrator**\n",
    "- Linux Terminal:```sudo python -m spacy download en ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part of Speech Tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "how_q_ex = 'How can I pay for my orders?'\n",
    "assertion_ex = 'I make an order by mistake. I won’t pay.'\n",
    "specific_qex = 'Can I use paypal for order #123?'\n",
    "when_q_ex = 'When can I get my cashback?'\n",
    "spelling_ex = 'My order number is #123. How can I pay?'\n",
    "\n",
    "examples = [how_q_ex, assertion_ex, specific_qex, when_q_ex, spelling_ex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\t|lemma\t|postag\t|tag\t|tag_explain\t\t\t\t   |dep_parser\t   |dep_explain\t\t|stop_word\n",
      "I       |-PRON- |PRON   |PRP    |pronoun, personal                         |nsubj          |nominal subject          |0      \n",
      "make    |make   |VERB   |VBP    |verb, non-3rd person singular present     |ROOT           |None                     |1      \n",
      "an      |an     |DET    |DT     |determiner                                |det            |determiner               |1      \n",
      "order   |order  |NOUN   |NN     |noun, singular or mass                    |dobj           |direct object            |0      \n",
      "by      |by     |ADP    |IN     |conjunction, subordinating or preposition |prep           |prepositional modifier   |1      \n",
      "mistake |mistake|NOUN   |NN     |noun, singular or mass                    |pobj           |object of preposition    |0      \n",
      ".       |.      |PUNCT  |.      |punctuation mark, sentence closer         |punct          |punctuation              |0      \n",
      "I       |-PRON- |PRON   |PRP    |pronoun, personal                         |nsubj          |nominal subject          |0      \n",
      "wo      |will   |VERB   |MD     |verb, modal auxiliary                     |aux            |auxiliary                |0      \n",
      "n’t     |not    |ADV    |RB     |adverb                                    |neg            |negation modifier        |0      \n",
      "pay     |pay    |VERB   |VB     |verb, base form                           |ROOT           |None                     |0      \n",
      ".       |.      |PUNCT  |.      |punctuation mark, sentence closer         |punct          |punctuation              |0      \n"
     ]
    }
   ],
   "source": [
    "doc = nlp(assertion_ex)\n",
    "print(f'text\\t|lemma\\t|postag\\t|tag\\t|tag_explain\\t\\t\\t\\t   |dep_parser\\t   |dep_explain\\t\\t|stop_word')\n",
    "for token in doc:\n",
    "    dep_explain = spacy.explain(token.dep_)\n",
    "    if type(dep_explain)==type(None):\n",
    "        dep_explain = 'None'\n",
    "    \n",
    "    tag_explain = spacy.explain(token.tag_)   \n",
    "    print(f'{token.text:<8}|{token.lemma_:<7}|{token.pos_:<7}|{token.tag_:<7}|{tag_explain:42}|{token.dep_:15}|{dep_explain:<25}|{token.is_stop:<7}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a wealth of detail in a single pipeline output. For instance, in the above example notice how spaCy assigns a Part-of-Speech tag to every token. These tags can be passed to your pipeline as a feature too, depending on the use case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nirantk\\Anaconda3\\envs\\fastai\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\Users\\nirantk\\Anaconda3\\envs\\fastai\\lib\\runpy.py:193: DeprecationWarning: Positional arguments to Doc.merge are deprecated. Instead, use the keyword arguments, for example tag=, lemma= or ent_type=.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1550\" height=\"362.0\" style=\"max-width: none; height: 362.0px; color: white; background: #09a3d5; font-family: Source Sans Pro\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">make</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">an</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">order</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">by</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">mistake.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">wo</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">n’t</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\">pay.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M62,227.0 62,202.0 194.0,202.0 194.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,229.0 L58,221.0 66,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M362,227.0 362,202.0 494.0,202.0 494.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M362,229.0 L358,221.0 366,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M212,227.0 212,177.0 497.0,177.0 497.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M497.0,229.0 L501.0,221.0 493.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M512,227.0 512,202.0 644.0,202.0 644.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M644.0,229.0 L648.0,221.0 640.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M662,227.0 662,202.0 794.0,202.0 794.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M794.0,229.0 L798.0,221.0 790.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M962,227.0 962,152.0 1400.0,152.0 1400.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M962,229.0 L958,221.0 966,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M1112,227.0 1112,177.0 1397.0,177.0 1397.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1112,229.0 L1108,221.0 1116,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M1262,227.0 1262,202.0 1394.0,202.0 1394.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1262,229.0 L1258,221.0 1266,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options = {'compact': True, \n",
    "           'bg': '#09a3d5',\n",
    "#            'bg': '#000',\n",
    "           'color': 'white', 'font': 'Source Sans Pro'}\n",
    "\n",
    "displacy.render(doc, jupyter=True, style='dep', options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun chunks\n",
    "\n",
    "Sometimes, we want to quickly pull out keywords, or keyphrases from a larger body of text. This helps us mentally paint a picture of what this text is about. This is particularly helpful in analysis of texts like email length. \n",
    "\n",
    "We refer to these as noun chunks. Noun chunks are _noun phrases_ - not a single word, but a short phrase which describes the noun. For example, \"the blue skies\" or \"the world’s largest conglomerate\". \n",
    "\n",
    "To get the noun chunks in a document, simply iterate over Doc.noun_chunks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_sentence = 'James B. Comey, the former F.B.I. director fired by President Trump, said in an ABC News interview that Mr. Trump was “morally unfit to be president,” portraying him as a danger to the nation.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "doc = nlp(example_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James B. Comey                ,Comey          ,nsubj  ,nominal subject          ,said           \n",
      "the former F.B.I. director    ,director       ,appos  ,appositional modifier    ,Comey          \n",
      "President Trump               ,Trump          ,pobj   ,object of preposition    ,by             \n",
      "an ABC News interview         ,interview      ,pobj   ,object of preposition    ,in             \n",
      "Mr. Trump                     ,Trump          ,nsubj  ,nominal subject          ,was            \n",
      "president                     ,president      ,attr   ,attribute                ,be             \n",
      "him                           ,him            ,dobj   ,direct object            ,portraying     \n",
      "a danger                      ,danger         ,pobj   ,object of preposition    ,as             \n",
      "the nation                    ,nation         ,pobj   ,object of preposition    ,to             \n"
     ]
    }
   ],
   "source": [
    "for chunk in doc.noun_chunks:\n",
    "    print(f'{chunk.text:<30},{chunk.root.text:<15},{chunk.root.dep_:<7},{spacy.explain(chunk.root.dep_):25},{chunk.root.head.text:<15}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastAI",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
