{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining \n",
    "### Information Extraction \n",
    "\n",
    "This notebook covers the simple but a powerful tool in text processing: **Regex**. Regex is extremely powerful for pulling out specific pieces of information which match a pattern. \n",
    "\n",
    "While regex is extremely powerful, it is slow when you have to run multiple regex of similar type over a single document. \n",
    "\n",
    "We will see how [FlastText](https://github.com/vi3k6i5/flashtext) helps speed this up by 5-10X. FlashText has seen lot of love from community. Adopters include [NLProc](https://github.com/NIHOPA/NLPre) - the NLP Preprocessing Toolkit from National Institute of Health. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python 3.6.4 :: Anaconda, Inc.\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "__author__ = \"nirant.bits@gmail.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spell Correction\n",
    "One of the most frequently seen text challenges is correcting spellings. This is even all the more true when data is entered by casual human users, for instance, say shipping addresses or similar. \n",
    "\n",
    "Let's take an example, we want to correct `Gujrat`, `Gujart` and other minor misspelligns to  `Gujarat`.\n",
    "There are several good ways to do this, depending on your dataset, and level of expertise. We discuss 2-3 popular ways, and discuss their pros and cons. \n",
    "\n",
    "Before I begin, we need to pay our homage to the legendary [Peter Norvig's Spell Correct](https://norvig.com/spell-correct.html). It's stil worth a read on how to _think_ about solving a problem and _exploring_ implementations. Even the way he refactors his code and writes functions is educational. \n",
    "\n",
    "His spell correction module is not the simplest or best way. I recommend two packages: one with a bias towards simplicity, one with a bias towards giving you all the knives, bells and whistles to try:\n",
    "\n",
    "**[FuzzyWuzzy](https://github.com/seatgeek/fuzzywuzzy)** is easy to use. It gives a simple similarity score between two strings, capped to 100. Higher numbers mean the words are more similar. \n",
    "\n",
    "**[Jellyfish](https://github.com/jamesturk/jellyfish)** supports 6 edit distance functions and 4 phonetic encoding options which you can use as per your use case. \n",
    "\n",
    "## FuzzyWuzzy\n",
    "\n",
    "If you have heard or used the [Levenshtein distance](https://www.wikiwand.com/en/Levenshtein_distance) (or, _edit distance_ functions in general), this package is a wrapper over the same. It uses difflib from the standard Python libs as well. \n",
    "\n",
    "Let's see how we can use FuzzyWuzzy to correct our misspellings:\n",
    "\n",
    "**Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy[speedup] in c:\\users\\nirantk\\anaconda3\\envs\\fastai\\lib\\site-packages\n",
      "Collecting python-levenshtein>=0.12; extra == \"speedup\" (from fuzzywuzzy[speedup])\n",
      "  Downloading python-Levenshtein-0.12.0.tar.gz (48kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nirantk\\anaconda3\\envs\\fastai\\lib\\site-packages (from python-levenshtein>=0.12; extra == \"speedup\"->fuzzywuzzy[speedup])\n",
      "Building wheels for collected packages: python-levenshtein\n",
      "  Running setup.py bdist_wheel for python-levenshtein: started\n",
      "  Running setup.py bdist_wheel for python-levenshtein: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\nirantk\\AppData\\Local\\pip\\Cache\\wheels\\c0\\83\\e9\\b2cc2876e175d04091caf4e9f5de564ff2503b1f1885e7c3ba\n",
      "Successfully built python-levenshtein\n",
      "Installing collected packages: python-levenshtein\n",
      "Successfully installed python-levenshtein-0.12.0\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install fuzzywuzzy\n",
    "# alternative for 4-10x faster computation: \n",
    "# !{sys.executable} -m pip install fuzzywuzzy[speedup]\n",
    "\n",
    "# Collecting fuzzywuzzy\n",
    "#   Downloading fuzzywuzzy-0.16.0-py2.py3-none-any.whl\n",
    "# Installing collected packages: fuzzywuzzy\n",
    "# Successfully installed fuzzywuzzy-0.16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.ratio(\"Electronic City Phase One\", \"Electronic City Phase One, Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.partial_ratio(\"Electronic City Phase One\", \"Electronic City Phase One, Bangalore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how the `ratio` function is confused by the trailing “Bangalore” used in address above, but really the two strings refer to the same address/entity. This is captured by `partial_ratio`. \n",
    "\n",
    "Note that how both `ratio` and `partial_ratio` are sensitive to ordering of the words. This is useful for comparing addresses, which follow a rough logical order. On the other hand, if we want to compare something else like person names, it might give counterintuitive results: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.ratio('Narendra Modi', 'Narendra D. Modi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.partial_ratio('Narendra Modi', 'Narendra D. Modi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrgh, this is not nice. Just because we had an extra `D.` token, our logic is less universal. We want something that is less order sensitive. Luckily, the authors of fuzzywuzzy kept this in mind. \n",
    "\n",
    "They support functions which tokenize our input on space, remove punctuations, numbers and non-ASCII characters. Then this is used to calculate similarity. Let's try that out: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.token_sort_ratio('Narendra Modi', 'Narendra D. Modi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.token_set_ratio('Narendra Modi', 'Narendra D. Modi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Nice, this works perfectly for us. In case we have a list of options and we want to find the closest match(es), we can use the process module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Gujarat', 92), ('Gujarat Govt.', 75), ('Gujjar', 67)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Gujarat', 92)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Gujrat'\n",
    "choices = ['Gujarat', 'Gujjar', 'Gujarat Govt.']\n",
    "# Get a list of matches ordered by score, default limit to 5\n",
    "print(process.extract(query, choices))\n",
    "\n",
    "# If we want only the top one\n",
    "process.extractOne(query, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Bangalore', 94), ('Bengaluru', 59)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Bangalore', 94)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Banglore'\n",
    "choices = ['Bangalore', 'Bengaluru']\n",
    "print(process.extract(query, choices))\n",
    "process.extractOne(query, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('chilli', 91), ('chilling', 77), ('chilled', 67)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('chilli', 91)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take an example of a common search typo in online shopping:\n",
    "query = 'chili'\n",
    "choices = ['chilli', 'chilled', 'chilling']\n",
    "print(process.extract(query, choices))\n",
    "process.extractOne(query, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Basic] Information Extraction\n",
    "\n",
    "As an example task, consider the challenge of automating Amazon Retail's customer service email response. We should be able to find the following attributes or mark them as missing with high confidence:\n",
    "\n",
    "- Order Id\n",
    "- Dates (such as Shopping Date, Order Delivery) \n",
    "- Any `$` amounts \n",
    "\n",
    "Please note that I don't have any relation to Amazon other than shopping from there. \n",
    "\n",
    "Let's consider the following totally imagined complaint email from me to Jeff Bezos, the CEO of Amazon:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "complaint_email = \"\"\"Hello Jeff,\n",
    "\n",
    "I am Nirant, a loyal Amazon in first customer for months now. I am a huge fan of Kindle as well. \n",
    "I am stuck in a new city without a phone thanks to a sequence of problems - and are now compounded by Amazon's inhumane behaviour.\n",
    "\n",
    "The particular issues I am facing: My new phone bought from Amazon stopped working. What did I do? Requested a replacement on Jul 23\n",
    "- First Issue: The system did not allow a pick up on July 23 forcing a delay of more than a day to 24 July 8:00 - 11:00 AM\n",
    "- Second Issue: Despite requesting the customer service on chat THRICE, the pickup is delayed to July 24 8:00 - 11:00 AM\n",
    "- Third Issue: The pickup is rescheduled without any reason!\n",
    "\n",
    "Is this how you want Amazon to be world's most customer centric company?\n",
    "\n",
    "Here is how Amazon can help me:\n",
    "- Pick up the order as urgently as possible\n",
    "- Deliver the phone on a priority basis on Monday i.e. July 25 itself\n",
    "\n",
    "Here are the order numbers for reference: \n",
    "ORDER # 402-4870778-5154753 and ORDER # 404-8689779-9721113\n",
    "\n",
    "Here is my phone number: +91 7737887058\n",
    "\n",
    "I am stuck in a new city, where I don't know the language or directions without a working phone. I would really appreciate it if you could help in anyway. \n",
    "\n",
    "Regards,\n",
    "Nirant Kasliwal\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes, that is a lot of text. \n",
    "\n",
    "**The information to pull from this are (1) dates + times (2) phone number and (3) order numbers**. Let's figure out how to do that\n",
    "\n",
    "### Extract Date and Times\n",
    "\n",
    "If you are new to regex, consider reading the amazing [HOWTO on Python Regex](https://docs.python.org/3/howto/regex.html) and then coming back here. Let's warm up our regex muscles a bit: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12', '11', '10']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = re.compile(r'\\d+')\n",
    "p.findall('12 drummers drumming, 11 pipers piping, 10 lords a-leaping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TKX: Add compile and findall explanations here\n",
    "\n",
    "TKX: Add d+ explanations here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "date_pattern = r\"^(Jan|Feb|Mar|Apr|May|Jun|July|Aug|Sep|Oct|Nov|Dec)$\"\n",
    "p = re.compile(date_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.findall(complaint_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastAI",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
